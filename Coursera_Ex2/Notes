Some points to note:
1. Loss function: Cross-entropy is used here. It is very similar to the gradient of sigmoid function. Here we just used the library code, imported as nn.functional.
2. Customized class: Note that we wrote a lot of functions and defined our own Mymodel Class. This could make our code precise. But also be careful how class can be defined. For example, self.linear is compulsory and you need to import nn and nn.Module as well.
3. Dataset and Dataloader are really useful.
4. Output of our model is similar to the probability that result could be in that class. Normal we could use Torch.max() to find the largest probability and thus the prediction.
5. It is not necessary to use the provided loss function in library. Your own function is also valid.
6. Note that normalization is very important for logistic regression otherwise you may find that the outputs are too large and activation function just become one.

Click on the following links to know more:
1. CrossEntropyLoss: https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html
2. Ds & Dl: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html
3. nn.Module: https://pytorch.org/docs/stable/generated/torch.nn.Module.html
4. Normalization of data: https://www.import.io/post/what-is-data-normalization-and-why-is-it-important/
