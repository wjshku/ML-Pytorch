{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8ac2150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from numpy import genfromtxt\n",
    "data = genfromtxt('C:/HKU/Self learning/Machine Learning/ex2/ex2data1.txt', delimiter=',')\n",
    "data = torch.from_numpy(data)\n",
    "data = data.chunk(3,1)\n",
    "norm1 = (data[0]-torch.mean(data[0]))/torch.pow(torch.var(data[0]),0.5)\n",
    "norm2 = (data[1]-torch.mean(data[1]))/torch.pow(torch.var(data[1]),0.5)\n",
    "inputs = torch.cat((norm1,norm2),1).float()\n",
    "targets = data[2].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "beb906db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "train_ds = TensorDataset(inputs,targets)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "# Define data loader\n",
    "batch_size = 100\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_dl = DataLoader(train_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c7e3f16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Mymodel(nn.Module):\n",
    "    def __init__(self,input_size,num_classes):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size,num_classes)\n",
    "    def train_step(self,batch):\n",
    "        inputs,targets = batch\n",
    "        outputs = self.linear(inputs)\n",
    "        targets = targets.squeeze(1).long()\n",
    "        #sigmoid = 1/(1+torch.exp(-outputs*0.01))\n",
    "        #loss = torch.sum(-torch.mul(targets, torch.log(sigmoid))-torch.mul(1-targets,torch.log(1-sigmoid)))\n",
    "        loss = F.cross_entropy(outputs, targets) # Calculate loss\n",
    "        return loss\n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch \n",
    "        out = self.linear(inputs)              # Generate predictions\n",
    "        targets = targets.squeeze(1).long()\n",
    "        loss = F.cross_entropy(out, targets)   # Calculate loss\n",
    "        #acc = accuracy(out, targets)           # Calculate accuracy\n",
    "        _, preds = torch.max(out,dim=1)\n",
    "        acc = torch.sum(preds==targets)/len(preds)\n",
    "        return {'val_loss': loss, 'val_acc': acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "240457a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoches,train_dl,model,loss_fn,opt):\n",
    "    for epoch in range(epoches):\n",
    "        for x,y in train_dl:\n",
    "            loss = loss_fn(model(x),y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print(\"Error:{} Epoch:[{}/{}]\".format(loss,epoch+1,epoches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ab022137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.6699, -0.3426],\n",
       "         [-0.5255, -0.2826]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1428, -0.6200], requires_grad=True)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Mymodel(2,2)\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0a2bb0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "976ee1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2430, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dl:\n",
    "    print(model.train_step(batch))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ee1a0d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1280, -1.5182],\n",
      "        [ 3.2881, -3.5623],\n",
      "        [ 0.4779, -1.6867],\n",
      "        [-2.2650,  0.7859],\n",
      "        [-2.5931,  1.6227],\n",
      "        [ 1.2610, -1.8432],\n",
      "        [-3.1850,  1.3695],\n",
      "        [ 0.0958, -0.1274],\n",
      "        [-3.4147,  2.0163],\n",
      "        [-0.2742,  0.4141]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "{'val_loss': tensor(0.2177, grad_fn=<NllLossBackward>), 'val_acc': tensor(0.8900)}\n",
      "tensor([[0.8384, 0.1616],\n",
      "        [0.9989, 0.0011],\n",
      "        [0.8970, 0.1030],\n",
      "        [0.0452, 0.9548],\n",
      "        [0.0145, 0.9855],\n",
      "        [0.9571, 0.0429],\n",
      "        [0.0104, 0.9896],\n",
      "        [0.5556, 0.4444],\n",
      "        [0.0044, 0.9956],\n",
      "        [0.3344, 0.6656]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(model.linear(inputs)[0:10])\n",
    "print(targets[0:10])\n",
    "for batch in val_dl:\n",
    "    result0 = model.validation_step(batch)\n",
    "    print(result0)\n",
    "    print(F.softmax(model.linear(inputs)[0:10], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "35d6994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs,train_dl,val_dl,model,opt):\n",
    "    history = []\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_dl:\n",
    "            loss = model.train_step(batch)     \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            break\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            for batch in val_dl:\n",
    "                result = model.validation_step(batch)\n",
    "                history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e7bda93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': tensor(1.2430, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.2000)},\n",
       " {'val_loss': tensor(0.7197, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.5500)},\n",
       " {'val_loss': tensor(0.5031, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8200)},\n",
       " {'val_loss': tensor(0.4099, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8700)},\n",
       " {'val_loss': tensor(0.3610, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8800)},\n",
       " {'val_loss': tensor(0.3311, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.3108, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2959, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.9000)},\n",
       " {'val_loss': tensor(0.2846, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.9000)},\n",
       " {'val_loss': tensor(0.2756, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.9000)},\n",
       " {'val_loss': tensor(0.2682, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.9000)}]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = [result0] + fit(100,train_dl,val_dl,model,opt)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f5075b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': tensor(0.2206, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2205, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2204, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2203, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2202, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2201, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2201, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2200, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2199, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2198, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2198, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2197, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2196, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2195, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2194, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2194, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2193, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2192, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2191, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2191, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history1 = fit(200,train_dl,val_dl,model,opt)\n",
    "history1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "920bfd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': tensor(0.2190, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2189, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2189, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2188, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2187, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2186, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2186, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2185, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2184, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2184, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2183, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2182, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2182, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2181, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2180, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2180, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2179, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2178, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2178, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)},\n",
       " {'val_loss': tensor(0.2177, grad_fn=<NllLossBackward>),\n",
       "  'val_acc': tensor(0.8900)}]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history2 = fit(200,train_dl,val_dl,model,opt)\n",
    "history2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14cc3d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "Predict: tensor([[5.6913e-01, 1.0000e+00],\n",
      "        [7.2447e-17, 1.0000e+00]], grad_fn=<MulBackward0>), Real: tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "number = torch.randint(0,100,(1,)).item()\n",
    "number = 2\n",
    "output = model.linear(inputs[0:number])\n",
    "prob = 1/(1+torch.exp(-output))\n",
    "print((prob > 0).long() - targets[0:number])\n",
    "print(\"Predict: {}, Real: {}\".format(prob,targets[number]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9ba03588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs,tagets):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    acc = torch.sum(preds==targets)/len(preds)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c30943d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -4.6764,  -3.7847],\n",
      "        [-27.0669, -26.5874],\n",
      "        [ -9.9690,  -8.8997],\n",
      "        [-16.0696, -15.4648],\n",
      "        [-22.3924, -21.5698]], grad_fn=<SliceBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1])\n",
      "tensor([0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1])\n",
      "tensor(0.6000)\n"
     ]
    }
   ],
   "source": [
    "for batch in val_dl:\n",
    "    inputs, targets = batch \n",
    "    out = model.linear(inputs)              # Generate predictions\n",
    "    print(out[95:])\n",
    "    targets = targets.squeeze(1).long()\n",
    "    _, preds = torch.max(out,dim=1)\n",
    "    print(preds)\n",
    "    print(targets)\n",
    "    acc = torch.sum(preds==targets)/len(preds)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "128a1514",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'coursera-ex2-simplelogistic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dab441ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "583426ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = history + history1 + history2\n",
    "accuracies = [result['val_acc'] for result in history]\n",
    "plt.plot(accuracies, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "56765369",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.zeros(2,2,requires_grad=True)\n",
    "b = torch.tensor([[0.,1.]],requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "18520ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smallmodel(inputs,w,b):\n",
    "    return inputs @ w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "36090464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.3964, Accuracy: 0.9000\n",
      "Epoch [20/100], Loss: 0.3904, Accuracy: 0.9200\n",
      "Epoch [30/100], Loss: 0.3849, Accuracy: 0.9200\n",
      "Epoch [40/100], Loss: 0.3797, Accuracy: 0.9200\n",
      "Epoch [50/100], Loss: 0.3748, Accuracy: 0.9100\n",
      "Epoch [60/100], Loss: 0.3701, Accuracy: 0.9200\n",
      "Epoch [70/100], Loss: 0.3657, Accuracy: 0.9200\n",
      "Epoch [80/100], Loss: 0.3616, Accuracy: 0.9200\n",
      "Epoch [90/100], Loss: 0.3577, Accuracy: 0.9200\n",
      "Epoch [100/100], Loss: 0.3539, Accuracy: 0.9200\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "lamb = 0.01\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs,targets in train_dl:\n",
    "        outputs = smallmodel(inputs,w,b)\n",
    "        targets = targets.squeeze(1).long()\n",
    "        loss = F.cross_entropy(outputs, targets)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            w -= lamb * w.grad #Bear in mind that we should not expand this thing, otherwise we get NoneType error\n",
    "            b -= lamb * b.grad\n",
    "            w.grad.zero_()\n",
    "            b.grad.zero_()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.4f}'.format(epoch+1, num_epochs, loss.item(),accuracy(outputs,targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "987eb666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 1])\n",
      "tensor([0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "_,preds = torch.max(smallmodel(inputs,w,b),dim = 1)\n",
    "print(preds)\n",
    "print(targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
